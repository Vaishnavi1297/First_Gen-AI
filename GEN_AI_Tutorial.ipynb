{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M4AvwvM3ukFe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 1. Creating a 3x3 matrix of random numbers\n",
        "np_array = np.random.rand(3, 3)\n",
        "pt_tensor = torch.rand(3, 3)\n",
        "\n",
        "# 2. Basic Math (Element-wise addition)\n",
        "np_result = np_array + 5\n",
        "pt_result = pt_tensor + 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJQB8lZa_1o3",
        "outputId": "e3206a69-4a7d-4f94-8ab5-9235bed039ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79704808, 0.59797664, 0.78709608],\n",
              "       [0.66110934, 0.75883243, 0.55849891],\n",
              "       [0.24013536, 0.71570651, 0.15761986]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwKpqtdS_9Oq",
        "outputId": "6d913fdb-36c4-485e-99a0-1b048a0fae11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7961, 0.6695, 0.4583],\n",
              "        [0.4069, 0.4617, 0.2770],\n",
              "        [0.7503, 0.8577, 0.9876]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_tensor = torch.zeros(5,5)\n",
        "zero_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dBBCNS6_-jb",
        "outputId": "03094725-74fa-4273-8e15-8f2fc214c3a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEhty5LeDFBT",
        "outputId": "8895bbc2-f286-4d1c-f3bc-42f21cbdb96c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the tensor to the GPU\n",
        "pt_tensor_gpu = pt_tensor.to('cuda')"
      ],
      "metadata": {
        "id": "QWtssuUTFPDB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_tensor_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIpXUS6cFTgu",
        "outputId": "3772df8d-d568-473a-b7cb-46535de04a4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7961, 0.6695, 0.4583],\n",
              "        [0.4069, 0.4617, 0.2770],\n",
              "        [0.7503, 0.8577, 0.9876]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to convert the GPU tensor back to NumPy\n",
        "pt_tensor_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "9qc4F0Q3GBbE",
        "outputId": "4ea1ea7f-8e4d-4457-8757-66d79ccdae85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3803980708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try to convert the GPU tensor back to NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpt_tensor_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##AIzaSyAOShOR7uhL3wT195GnPwbpY36KmZRvmpQ"
      ],
      "metadata": {
        "id": "qY_JrRQJGZXQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "4VDeUeCrNN97"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Fetch the key securely from the Secrets Manager\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# 2. Configure the SDK\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# 3. Load the model (We'll use 'gemini-1.5-flash' for speed)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "print(\"Ready to generate!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ1IMoIJNQ3M",
        "outputId": "15e42eed-01f0-4a1d-daf2-06130ef366f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to generate!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all models available to your API key\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "x6-n_CEk_TA8",
        "outputId": "173861e5-1f51-4aab-f463-42f9a1e7b96e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Update the model name to one from your list\n",
        "model = genai.GenerativeModel('models/gemini-flash-latest')\n",
        "\n",
        "# 2. The confusing code and prompt are the same as before\n",
        "cryptic_code = \"print('\\n'.join([' '.join(['*' for _ in range(i)]) for i in range(1, 6)]))\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are an expert Python tutor. Explain what the following code does in one sentence,\n",
        "then show what the output would look like.\n",
        "\n",
        "Code:\n",
        "{cryptic_code}\n",
        "\"\"\"\n",
        "\n",
        "# 3. Send it to the model\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# 4. Print the result\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "wuoAWqF1NrUJ",
        "outputId": "8561e865-98f7-40e5-da13-8513e96f2bd3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code constructs a list of increasing strings of space-separated asterisks (from one to five stars) and then prints each string on a new line, forming a right-aligned triangle.\n",
            "\n",
            "***\n",
            "\n",
            "## Output:\n",
            "\n",
            "```\n",
            "*\n",
            "* *\n",
            "* * *\n",
            "* * * *\n",
            "* * * * *\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get input dynamically from the user\n",
        "user_code = input(\"Paste the code you want explained: \")\n",
        "\n",
        "# 2. Construct the prompt using the user's input\n",
        "prompt = f\"\"\"\n",
        "You are an expert Python tutor. Explain what the following code does in one sentence,\n",
        "then show what the output would look like.\n",
        "\n",
        "Code:\n",
        "{user_code}\n",
        "\"\"\"\n",
        "\n",
        "# 3. Generate and print\n",
        "response = model.generate_content(prompt)\n",
        "print(\"\\n--- AI Explanation ---\\n\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "OUOEaPsGN-Tg",
        "outputId": "f0f46526-01f3-4857-c442-d3e134ebe1c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste the code you want explained: [x**2 for x in range(10) if x % 2 == 0]\n",
            "\n",
            "--- AI Explanation ---\n",
            "\n",
            "As an expert Python tutor, I can explain that this code uses a list comprehension to efficiently generate a new list.\n",
            "\n",
            "### Explanation (One Sentence)\n",
            "\n",
            "This list comprehension constructs a list containing the squares of all even integers between 0 and 9, inclusive.\n",
            "\n",
            "***\n",
            "\n",
            "### Output\n",
            "\n",
            "```\n",
            "[0, 4, 16, 36, 64]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2ae_yJqBBXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}